{
 "metadata": {
  "name": "IGG"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import re, os, sys\nimport urllib\nimport BeautifulSoup as bs\nfrom bs4 import BeautifulSoup\nimport pandas as pd\nfrom dateutil import parser\nfrom geopy import geocoders\nfrom itertools import izip\nimport numpy as np\nimport requests\nfrom datetime import datetime\nimport twitter\nfrom twitter import OAuth\nfrom twitter import Twitter\n\nimport gdata.youtube\nimport gdata.youtube.service\nyt_service = gdata.youtube.service.YouTubeService()\nyt_service.ssl = True\nyt_service = gdata.youtube.service.YouTubeService()\n\ng = geocoders.GoogleV3()\nfailures = []\nperks = {}\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "f=open(\"igg_link.txt\")\nf=f.read()\nf=f.split(\"\\n\")\nlen(f)\ncomment_link=[]\nfor i in f:\n    comment_link.append(\"http://www.indiegogo.com/projects/{}\".format(i))",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "len(comment_link)",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": "1585"
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def dc_dist(location):\n    from geopy import distance\n    _, cl = g.geocode('Washington, D.C.')\n    try:\n        _, ne = g.geocode(location)\n        dist=distance.distance(ne, cl).miles\n        return dist\n    except:\n        return \"NA\"",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from HTMLParser import HTMLParser\n\nclass MLStripper(HTMLParser):\n    def __init__(self):\n        self.reset()\n        self.fed = []\n    def handle_data(self, d):\n        self.fed.append(d)\n    def get_data(self):\n        return ' '.join(self.fed)\n\ndef strip_tags(html):\n    s = MLStripper()\n    s.feed(html)\n    return s.get_data()",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Getting perks data"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def perksdata(link):\n    data=(urllib.urlopen(link))\n    data=str(data.read())\n    p1 = re.compile('<section class=\\\"perks\\\">(.*?)\\</section>', re.IGNORECASE|re.DOTALL)\n    datapart2 = str(re.findall(p1, str(data)))\n    p12 = re.compile('<p class=\\\"fl claimed big-perk-button\\\">(.*?)\\</p>', re.IGNORECASE|re.DOTALL)\n    claims = str(re.findall(p12, str(datapart2)))\n    #print claims\n    claims=claims.split(\"\\\\n\")\n    #claims=claims.split(\",\")\n    #print claims\n    #print len(claims)\n    claimed=[]\n    for i in claims:\n        temp_perk  = re.findall('\\d+',i)\n        if len(temp_perk)>0:\n            claimed.append(float(temp_perk[0]))\n    #print claimed\n    p13 = re.compile('<span class=\\\"currency currency-large\\\">(.*?)\\</span>', re.IGNORECASE|re.DOTALL)\n    tmpamount = str(re.findall(p13, str(datapart2)))[1:-1]\n    tmpamount=tmpamount.split(\" \")\n    perk_amount=[]\n    #print tmpamount\n    try:\n        for i in tmpamount:\n            i=i.replace(\",\", \"\")\n            amt  = re.findall('\\d+',i)\n            perk_amount.append(int(amt[0]))\n        no_perks = len(perk_amount)\n        #print perk_amount\n        median  = np.median(np.array(perk_amount))\n        try:\n            no_median_perk =  claimed[perk_amount.index(median)]\n        except:\n            no_median_perk = 0   \n        perk_amount = np.array(perk_amount)\n        #perk_amount_min = np.array(perk_amount).argmin()\n        maxperk = perk_amount.max()\n        minperk = perk_amount.min()\n        no_min_perk =  claimed[perk_amount.argmin()]\n        no_max_perk =  claimed[perk_amount.argmax()]\n        res = (minperk,no_min_perk,maxperk,no_max_perk,median,no_median_perk,no_perks)\n        return res\n    except:\n        #failures.append((link,\"perks data\"))\n        res = ()\n        return res\n        ",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Social media data"
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": "Initializing keys"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "twitterapi = Twitter(auth=OAuth(\n        '99045947-JUBOFYWz3G7vprh81BBLTONVbZUsRxQtwSsqE3v0Q', 'rx2rNaaEpTvDgLUI9vxms8r4sGrUHyQcYwcBm5wc', \n        'XGg0jqHyJQXuuauFVQywSQ', 'VP5zLNdesKjN0eelyU9vemBn2dXQcOaBZMn7xGvIG8'))\n\nfb_base_url = 'https://graph.facebook.com/'",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": "Facebook"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Facebook data\ndef getfbdata(user):\n    url = fb_base_url + user \n    response = requests.get(url)\n    profile = response.json()\n    likes = profile['likes']\n    talking = profile['talking_about_count']\n    return (likes, talking)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 85
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": "Twitter"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Twitter Data\ndef gettwitterdata(handle):\n    #print handle\n    user = twitterapi.GetUser(screen_name=handle)\n    return (user.GetFollowersCount(), user.GetStatusesCount())",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "heading",
     "level": 4,
     "metadata": {},
     "source": "Youtube"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 86
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def yt(entr):\n    try:\n        entry = yt_service.GetYouTubeVideoEntry(video_id=entr)\n        try:\n            dur = entry.media.duration.seconds\n        except:\n            dur = 0\n        try:\n            cnt = entry.statistics.view_count\n        except:\n            cnt= 0\n        try:\n            rating = entry.rating.average\n        except:\n            rating = 0 \n        #print dur,cnt,rating\n        return (dur,cnt,rating)\n    except:\n        return (0,0,0)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def you(link):\n    dur = 0.0\n    vcount = 0.0\n    avgrating = 0.0\n    counter = 0 \n    try:\n        if link.startswith(\"http://youtu.be\"):\n            dur,vcount,avgrating = yt(link[15:])\n            return (dur,vcount,avgrating)\n            #you_final.append((link, link[15:]))\n        else:\n            test= urllib.urlopen(link).read()\n            test=BeautifulSoup(test)\n            temp = set()\n            \n            for anchor in test.findAll('a', href=True):\n                    x= (anchor['href'])\n                    if (x.startswith(\"/watch\")):\n                        if (len(x[9:])==11):\n                            temp.add(x[9:])\n            temp =list(temp)\n            for video in temp:\n                counter +=1\n                data = yt(video)\n                dur = dur + float(data[0])\n                vcount = vcount + float(data[1])\n                avgrating = avgrating + float(data[2])\n            return (float(dur)/counter,float(vcount)/counter,float(avgrating)/counter)\n    except:\n        return ('NA','NA','NA')",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 88
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#Getting social media data\ndef soc(link):\n    test=urllib.urlopen(link).read()\n    test=BeautifulSoup(test)\n    test=test.findAll(\"ul\", class_=\"fr links\")\n    test=BeautifulSoup(str(test))\n    test=test.findAll(\"li\")\n    test=BeautifulSoup(str(test))\n    fblikes = 'NA'\n    fbtalking ='NA'\n    tfollowercnt = 'NA'\n    tstatuscnt ='NA'\n    youdur = 'NA'\n    youviewcnt = 'NA'\n    youavgratig = 'NA'\n    for anchor in test.findAll('a', href=True):\n        soclink = anchor['href']\n        #print soclink\n        try:\n            if ('facebook' in soclink):\n                #print \"iside fb\"\n                fbdata =  getfbdata(soclink[25:])\n                #print fbdata\n                fblikes = fbdata[0]\n                fbtalking = fbdata[1]\n        except:\n            pass\n        try:\n            if ('twitter' in soclink):\n                twitterdata =  gettwitterdata(soclink[20:])\n                tfollowercnt = twitterdata[0]\n                tstatuscnt = twitterdata[1]\n        except:\n            pass\n        try:\n            if ('youtube' in soclink):\n                #print \"this is inside youtube\",soclink\n                youtubedata = you(soclink)\n                youdur = youtubedata[0]\n                youviewcnt = youtubedata[1]\n                youavgratig = youtubedata[2]\n        except:\n            pass\n    return (fblikes,fbtalking,tfollowercnt,tstatuscnt,youdur,youviewcnt,youavgratig)",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 89
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print soc(\"http://www.indiegogo.com/projects/beddit-automatic-sleep-and-wellness-tracker-turn-your-bed-into-a-smart-bed\")",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "(817, 36, 'NA', 'NA', 736.8888888888889, 1417.5555555555557, 3.285712416666667)\n"
      }
     ],
     "prompt_number": 90
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Getting project details"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def proj_head(link):\n    minperk = \"NA\"\n    no_min_perk = \"NA\"\n    maxperk = \"NA\"\n    no_max_perk = \"NA\"\n    median_perk = \"NA\"\n    no_med_perk = \"NA\"\n    total_perks =\"NA\"\n    fblikes = 'NA'\n    fbtalking ='NA'\n    tfollowercnt = 'NA'\n    tstatuscnt ='NA'\n    youdur = 'NA'\n    youviewcnt = 'NA'\n    youavgratig = 'NA'\n    US=0\n    current=0\n#     proj_page=\"http://www.indiegogo.com/\"+link_page[n]\n    proj_page=urllib.urlopen(link).read()\n    soup_page=BeautifulSoup(proj_page)\n    head=soup_page.find_all(\"div\", class_=\"sub-header\")\n    head=str(head)\n    head=BeautifulSoup(str(head))\n    head_line=head.find_all(\"h1\", class_=\"bold x-large notranslate\")\n    head_line=strip_tags(str(head_line))[1:-1]\n    head_line = re.sub(r\"[\\n\\t\\r]\", \"\",head_line)\n    # print head_line\n    desc_short=head.find_all(\"p\", class_=\"notranslate\")\n    desc_short=strip_tags(str(desc_short))[1:-1]\n    desc_short = re.sub(r\"[\\n\\t\\r]\", \"\",desc_short)\n    # print desc_short\n    category=head.find_all(\"span\", class_=\"category\")\n    category=strip_tags(str(category))[2:-2]\n    # print category\n    location=head.find_all(\"span\", class_=\"location\")\n    location=strip_tags(str(location))[2:-2]\n    country=location.split(\",\")[-1][1:]\n    # print location\n    if country == \"United States\":\n        US=1\n    #distance=dc_dist(location)\n    distance = \"NA\"\n    proj=str(head.find_all(\"div\", class_=\"project\"))\n    proj=proj.split(\"</li>\")\n    try:\n        for i in range(1, 5):\n            count_update= strip_tags(str(proj[1]))[10:]\n            count_comment= strip_tags(str(proj[2]))[11:]\n            count_funder= strip_tags(str(proj[3]))[10:]\n            count_photo= strip_tags(str(proj[4]))[10:]\n        amount_det=soup_page.find_all(\"div\", class_=\"targets clearfix\")\n        amount_det=BeautifulSoup(str(amount_det))\n        amount_raise=strip_tags(str(amount_det.find_all(\"span\", class_=\"amount medium clearfix\")))\n        #print \"amount raise %s\" %(amount_raise)\n        #amount_raised= re.findall('\\d+',amount_raise)  #amount_raise[2:-4]\n        amount_raise=amount_raise.replace(\",\",\"\")\n        amount_raised= \"\".join(re.findall('\\d+',amount_raise))\n        #print \"amount raised %s\" %(amount_raised)\n        amount_cur=amount_raise[-4:-1]\n        amount_goal=strip_tags(str(amount_det.find_all(\"p\", class_=\"money-raised goal\")))[19:-10]\n        amount_goal=amount_goal.replace(\",\",\"\")\n        amount_goal= \"\".join(re.findall('\\d+',amount_goal))\n        #print \"amountgoal\", amount_goal\n        #print \"amount goal %s\" %(amount_goal)\n        #ratio=0\n        ratio= float(amount_raised)/float(amount_goal)\n        time_left= strip_tags(str(amount_det.find_all(\"p\", class_=\"days-left\")))[2:-22]\n        time_left = time_left.strip()\n        if time_left != 0:\n            current=1\n        amount_tpe=soup_page.find_all(\"div\", class_=\"contribution-info\")\n        amount_tpe=BeautifulSoup(str(amount_tpe))\n        amount_type=strip_tags(str(amount_tpe.find_all(\"p\", class_=\"amount bold fl title\")))[1:-1]\n        amount_time=strip_tags(str(amount_tpe.find_all(\"p\", class_=\"funding-info\")))[1:-1].split(\".\")[1][18:-13]\n        amount_start_time=amount_time.split(\"-\")[0].replace(\",\",\"\")\n        amount_end_time=amount_time.split(\"-\")[1].replace(\",\",\"\")\n        delta=(parser.parse(amount_end_time)-parser.parse(amount_start_time)).total_seconds()\n    \n        amount_start_time = parser.parse(amount_start_time)\n        start_year = amount_start_time.year\n        start_month = amount_start_time.month\n        start_day = amount_start_time.day\n        amount_end_time = parser.parse(amount_end_time)\n        end_year = amount_end_time.year\n        end_month = amount_end_time.month\n        end_day = amount_end_time.day\n        #print start_year,start_month,end_year,end_day\n    #     print amount_type, parser.parse(amount_start_time), parser.parse(amount_end_time)\n        perks_data = perksdata(link)\n        if len(perks_data)>0:\n            minperk = perks_data[0]\n            no_min_perk = perks_data[1]\n            maxperk = perks_data[2]\n            no_max_perk = perks_data[3]\n            median_perk = perks_data[4]\n            no_med_perk = perks_data[5]\n            total_perks = perks_data[6]\n        #print \"<Perks>\"\n        #print perks_data\n        #print \"</Perks>\"\n        print \"Success\",link\n        if (link):\n            title = link[34:]\n        else:\n            title=\"\"\n        \n        #Getting social media statistics\n        try:\n            socdata = soc(link)\n            fblikes = socdata[0]\n            fbtalking = socdata[1]\n            tfollowercnt = socdata[2]\n            tstatuscnt = socdata[3]\n            youdur = socdata[4]\n            youviewcnt = socdata[5]\n            youavgratig = socdata[6]\n        except:\n            pass \n        return (title,head_line.strip(), desc_short.strip(), category.strip(), location.strip(), country.strip(), US, \n        distance, count_update, count_comment, count_funder, count_photo, amount_goal, \n        amount_raised, amount_cur, ratio, time_left, current, amount_type, start_year,start_month,start_day, end_year,end_month,end_day,\n        delta,minperk,no_min_perk,maxperk,no_max_perk,median_perk ,no_med_perk,total_perks,\n        fblikes,fbtalking,tfollowercnt,tstatuscnt,youdur,youviewcnt,youavgratig)\n    except:\n        failures.append((link,\"proj_headmethod\"))\n",
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 91
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print proj_head(\"http://www.indiegogo.com/projects/beddit-automatic-sleep-and-wellness-tracker-turn-your-bed-into-a-smart-bed\")",
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "Success http://www.indiegogo.com/projects/beddit-automatic-sleep-and-wellness-tracker-turn-your-bed-into-a-smart-bed\n('beddit-automatic-sleep-and-wellness-tracker-turn-your-bed-into-a-smart-bed', '', 'The Beddit sensor tracks your sleep quality, heart rate, and breathing under the sheet while you sleep. The app coaches you to improve sleep and performance.', 'Technology', 'Saratoga, California, United States', 'United States', 0, 'NA', '15', '501', '3981', '', '80000', '503571', 'SD ', 6.2946375, '0', 1, ' Flexible Funding ', 2013, 8, 2, 2013, 10, 15, 6393600.0, 10, 30.0, 7900, 3.0, 449.0, 26.0, 7, 817, 36, 'NA', 'NA', 736.8888888888889, 1417.5555555555557, 3.285712416666667)"
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": "\n"
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "projdata=[]\nfor proj in comment_link[1000:1500]:\n    projdata.append(proj_head(proj))\ndf = pd.DataFrame(projdata)\n#df.to_csv(\"projdata.csv\",sep='\\t',header=False)\nwith open('projdata.csv', 'a') as f:\n    df.to_csv(f,sep='\\t',header=False)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "projdata[99]",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def perksdata(link):\n    data=(urllib.urlopen(link))\n    data=str(data.read())\n    p1 = re.compile('<section class=\\\"perks\\\">(.*?)\\</section>', re.IGNORECASE|re.DOTALL)\n    datapart2 = str(re.findall(p1, str(data)))\n    p12 = re.compile('<p class=\\\"fl claimed big-perk-button\\\">(.*?)\\</p>', re.IGNORECASE|re.DOTALL)\n    claims = str(re.findall(p12, str(datapart2)))\n    #print claims\n    claims=claims.split(\"\\\\n\")\n    #claims=claims.split(\",\")\n    #print claims\n    #print len(claims)\n    claimed=[]\n    for i in claims:\n        temp_perk  = re.findall('\\d+',i)\n        if len(temp_perk)>0:\n            claimed.append(float(temp_perk[0]))\n    #print claimed\n    p13 = re.compile('<span class=\\\"currency currency-large\\\">(.*?)\\</span>', re.IGNORECASE|re.DOTALL)\n    tmpamount = str(re.findall(p13, str(datapart2)))[1:-1]\n    tmpamount=tmpamount.split(\" \")\n    perk_amount=[]\n    #print tmpamount\n    try:\n        for i in tmpamount:\n            i=i.replace(\",\", \"\")\n            amt  = re.findall('\\d+',i)\n            perk_amount.append(int(amt[0]))\n        no_perks = len(perk_amount)\n        #print perk_amount\n        median  = np.median(np.array(perk_amount))\n        try:\n            no_median_perk =  claimed[perk_amount.index(median)]\n        except:\n            no_median_perk = 0   \n        perk_amount = np.array(perk_amount)\n        #perk_amount_min = np.array(perk_amount).argmin()\n        maxperk = perk_amount.max()\n        minperk = perk_amount.min()\n        no_min_perk =  claimed[perk_amount.argmin()]\n        no_max_perk =  claimed[perk_amount.argmax()]\n        res = (minperk,no_min_perk,maxperk,no_max_perk,median,no_median_perk,no_perks)\n        return res\n    except:\n        #failures.append((link,\"perks data\"))\n        res = ()\n        return res\n        ",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "print perksdata(\"http://www.indiegogo.com/projects/defense-in-lawsuit-by-dutch-anti-piracy-organisation\")",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "s=\"$999,4000 CAD\"\nm = re.findall('\\d+', s)\nprint m\n\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "initialload = [(1,2,3,4,5,6),\n               (6,7,8,9,10,11),\n               (12,13,14,15,17,18),\n               (18,19,20,21,22,23)]\ndf = pd.DataFrame(initialload,columns=[\"num1\",\"num2\",\"num3\",\"num4\",\"num5\",\"num6\"])\ndf",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "df.to_csv(\"datatext.csv\",sep='\\t')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "initialload1 = [(11,2,3,4,5,6),\n               (61,7,8,9,10,11),\n               (112,13,14,15,17,18),\n               (181,19,201,21,22,23)]\ndf1 = pd.DataFrame(initialload1,columns=[\"num1\",\"num2\",\"num3\",\"num4\",\"num5\",\"num6\"])\ndf1",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "with open('datatext.csv', 'a') as f:\n    df1.to_csv(f,sep='\\t',header=False)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "dfnew = pd.DataFrame(l)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import re\n\nmystr = \"I want to Remove all white \\t spaces, new lines \\n and tabs \\t\"\nprint re.sub(r\"[\\n\\t]\", \"\", mystr)\n#print re.sub(r\"\\t\", \"\", mystr)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "failures\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}