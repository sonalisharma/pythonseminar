{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#!/usr/bin/env python\n",
      "\"\"\"\n",
      "AY 250 - Scientific Research Computing with Python\n",
      "Homework Assignment 4 - Parallel Feature Extraction Example\n",
      "Author: Christopher Klein, Joshua Bloom\n",
      "\"\"\"\n",
      "from os import listdir\n",
      "import os \n",
      "from multiprocessing import Pool, cpu_count\n",
      "from pylab import imread\n",
      "from time import time\n",
      "import scipy as sp\n",
      "import numpy as np\n",
      "from skimage.filter import sobel\n",
      "\n",
      "## CHANGE THIS NEXT LINE!\n",
      "MYDIRECTORY =\"/Users/sonali/Documents/Ischool/PythonSeminar/NewRepo/pythonseminar/HW4/validation_images\"\n",
      "\n",
      "# FUNCTION DEFINITIONS\n",
      "# Quick function to divide up a large list into multiple small lists, \n",
      "# attempting to keep them all the same size. \n",
      "def split_seq(seq, size):\n",
      "        newseq = []\n",
      "        splitsize = 1.0/size*len(seq)\n",
      "        for i in range(size):\n",
      "            newseq.append(seq[int(round(i*splitsize)):\n",
      "                int(round((i+1)*splitsize))])\n",
      "        return newseq\n",
      "# Our simple feature extraction function. It takes in a list of image paths, \n",
      "# does some measurement on each image, then returns a list of the image paths\n",
      "# paired with the results of the feature measurement.\n",
      "def extract_features(image_path_list):\n",
      "    feature_list = []\n",
      "    for image_path in image_path_list:\n",
      "        image_array = imread(image_path)\n",
      "        img_size = image_array.size\n",
      "        red_channel_mean= image_array[...,0].mean()\n",
      "        green_channel_mean= image_array[...,1].mean()\n",
      "        blue_channel_mean= image_array[...,2].mean()\n",
      "        red_channel_sd= image_array[...,0].std()\n",
      "        green_channel_sd= image_array[...,1].std()\n",
      "        blue_channel_sd= image_array[...,2].std()\n",
      "        try:\n",
      "            r, g, b = image_array[:,:,0], image_array[:,:,1], image_array[:,:,2]\n",
      "            imgarray1_gray = 0.2989 * r + 0.5870 * g + 0.1140 * b\n",
      "        except:\n",
      "            pass\n",
      "        max_gray_x_loc = np.argwhere(imgarray1_gray.max() == imgarray1_gray)[...,0].mean()\n",
      "        max_gray_y_loc = np.argwhere(imgarray1_gray.max() == imgarray1_gray)[...,1].mean()\n",
      "        min_gray_x_loc = np.argwhere(imgarray1_gray.min() == imgarray1_gray)[...,0].mean()\n",
      "        min_gray_y_loc = np.argwhere(imgarray1_gray.min() == imgarray1_gray)[...,1].mean()\n",
      "        min_gray_x_loc_std = np.argwhere(imgarray1_gray.min() == imgarray1_gray)[...,0].std()\n",
      "        min_gray_y_loc_std = np.argwhere(imgarray1_gray.min() == imgarray1_gray)[...,1].std()\n",
      "        max_gray_x_loc_std = np.argwhere(imgarray1_gray.max() == imgarray1_gray)[...,0].std()\n",
      "        max_gray_y_loc_std = np.argwhere(imgarray1_gray.max() == imgarray1_gray)[...,1].std()\n",
      "        \n",
      "        imgarray1_gray = np.array(imgarray1_gray, dtype=np.float64)\n",
      "        edges = sobel(imgarray1_gray)\n",
      "        edges_height = edges.shape[0]\n",
      "        edges_width = edges.shape[1]\n",
      "      \n",
      "        feature_list.append([image_path.split(\"/\")[-2],image_path.split(\"/\")[-1], \n",
      "                             img_size,\n",
      "                             red_channel_mean,\n",
      "                             green_channel_mean,\n",
      "                             blue_channel_mean,\n",
      "                             red_channel_sd,\n",
      "                             green_channel_sd,\n",
      "                             blue_channel_sd,\n",
      "                             max_gray_x_loc,\n",
      "                             max_gray_y_loc,\n",
      "                             min_gray_x_loc,\n",
      "                             min_gray_y_loc,\n",
      "                             max_gray_x_loc_std,\n",
      "                             max_gray_y_loc_std,\n",
      "                             min_gray_x_loc_std,\n",
      "                             min_gray_y_loc_std,\n",
      "                             edges_height,\n",
      "                             edges_width                              \n",
      "                             ])\n",
      "    return feature_list\n",
      "\n",
      "\n",
      "\n",
      "### Main program starts here ###################################################\n",
      "# We first collect all the local paths to all the images in one list\n",
      "image_paths = []\n",
      "categories = listdir(MYDIRECTORY)\n",
      "for category in categories:\n",
      "    if category == '.DS_Store':\n",
      "        pass\n",
      "    else:\n",
      "        image_names = listdir(MYDIRECTORY  + \"/\" + category)\n",
      "        for name in image_names:\n",
      "            image_paths.append(MYDIRECTORY + \"/\" + category + \"/\" + name)\n",
      "\n",
      "print (\"There should be 2123 images, actual number is \" + \n",
      "    str(len(image_paths)) + \".\")\n",
      "\n",
      "# Then, we run the feature extraction function using multiprocessing.Pool so \n",
      "# so that we can parallelize the process and run it much faster.\n",
      "numprocessors = cpu_count() # To see results of parallelizing, set numprocessors\n",
      "                            # to less than cpu_count().\n",
      "# numprocessors = 1\n",
      "\n",
      "# We have to cut up the image_paths list into the number of processes we want to\n",
      "# run. \n",
      "split_image_paths = split_seq(image_paths, numprocessors)\n",
      "\n",
      "# Ok, this block is where the parallel code runs. We time it so we can get a \n",
      "# feel for the speed up.\n",
      "start_time = time()\n",
      "p = Pool(numprocessors)\n",
      "result = p.map_async(extract_features, split_image_paths)\n",
      "poolresult = result.get()\n",
      "end_time = time()\n",
      "\n",
      "# All done, print timing results.\n",
      "print (\"Finished extracting features. Total time: \" + \n",
      "    str(round(end_time-start_time, 3)) + \" s, or \" + \n",
      "    str( round( (end_time-start_time)/len(image_paths), 5 ) ) + \" s/image.\")\n",
      "# This took about 10-11 seconds on my 2.2 GHz, Core i7 MacBook Pro. It may also\n",
      "# be affected by hard disk read speeds.\n",
      "\n",
      "# To tidy-up a bit, we loop through the poolresult to create a final list of\n",
      "# the feature extraction results for all images.\n",
      "combined_result = []\n",
      "for single_proc_result in poolresult:\n",
      "    for single_image_result in single_proc_result:\n",
      "        combined_result.append(single_image_result)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "There should be 4244 images, actual number is 2123.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Finished extracting features. Total time: 63.048 s, or 0.0297 s/image.\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from sklearn import metrics\n",
      "from collections import defaultdict\n",
      "import pickle\n",
      "from sklearn import preprocessing\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "results = defaultdict(list)\n",
      "pkl_file = open(\"trained_classifier.p\", 'rb')\n",
      "clf2 = pickle.load(pkl_file)\n",
      "X = [c[2:] for c in combined_result]\n",
      "X_scaled = preprocessing.scale(X)\n",
      "preds = clf2.predict(X_scaled)\n",
      "#Confusion matrix\n",
      "#rfor_accuracy_score = metrics.accuracy_score(X_scaled, preds) \n",
      "# create and save the confusion matrix\n",
      "#confmat = metrics.confusion_matrix(X_scaled, preds)\n",
      "#plt.imshow(confmat, interpolation=\"nearest\", origin=\"upper\")\n",
      "#plt.savefig(\"confusion_matrix.pdf\")\n",
      "#plt.close(\"all\")\n",
      "\n",
      "results_file = file(\"results.txt\", \"w\")\n",
      "results_file.write(\"Predicted image classes for Sonali Sharma's classifier\")\n",
      "#results_file.write(\"Accuracy score: \" + rfor_accuracy_score)\n",
      "results_file.write(\"\")\n",
      "results_file.write(\"filename\\t\\tpredicted_class\\n\")\n",
      "results_file.write(\"-----------------------------------------\\n\")\n",
      "for i in range(len(preds)):\n",
      "    results[X_scaled[i][1]]=preds[i]\n",
      "    results_file.write(combined_result[i][1]+\"\\t\"+preds[i]+\"\\n\")\n",
      "results_file.close()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "list indices must be integers, not tuple",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-16-81001dab0a7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mTypeError\u001b[0m: list indices must be integers, not tuple"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}